---
title: "What is GAN?"
date: 2020-08-20
categories: CycleGAN
---

`위 본문은 https://arxiv.org/abs/1703.10593의 논문과 다양한 글로 인해 작성가능했습니다`

## 왜 cycleGAN이 필요한가?


이전에 conditional GAN의 일종인 pix2pix를 이용하여 건물 형태의 input_data 즉 source data , 그에 pair가 되는 Ground Truth 즉 target_data를
입력받아 target image 를 기반으로 하는 이미지를 생성해내었다. 

![example](https://user-images.githubusercontent.com/65720894/90312851-cdb13600-df42-11ea-83fe-9399e2673332.PNG)

이러한 pix2pix는 훌룡한 성능을 보였지만 이미지 데이터가 pair형태여야지만 학습이 가능하다는 단점이 있다. 하지만 현실세계에서는 pair로 되어있는 데이터
는 극히 드믈다. 그래서 이러한 단점을 보완? 하기 위해 새로 고안된 아이디어가 CycleGAN이다.

![cyclegan](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcEqYf0%2FbtqCsHJvokH%2FsoUGLAYh2SFZ2bkKCW3im1%2Fimg.png)

예를 들어 위에 열심히 뛰고있는 말친구와 얼룩말이 보이는가? 실제로 내가 말을 얼룩말로 변환하고 싶어 pix2pix를 사용하기 위해서는 저 뛰어다니는 말친구와 똑같은 얼룩말 친구를 데려와야할것이다.
하지만 이는 매우 어려운 일이고 또하나의 예시인 photo - Van Gogh translation에서는 내가찍은 사진을 반 고흐 화가에게 그려달라고 할 수도 없는 노릇 아닌가?  
따라서 unpaired한 데이터를 이용해 학습시킬 방법이 필요했다.

## 이론

이전의 gan에서 하나의 적대적 학습구조를 더 만들고 이는 cycle형태를 띈다. 그림으로 보도록 하자

![ctclegan](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJWoX7%2FbtqCrPnUyaj%2FVFUXXFRz4FUyVjJd3xe810%2Fimg.png)

CycleGAN model 은 위이미지와 같이 `G:X → Y and F:Y → X`를 해주는 두개의 mapping fucction이 있고 F(Y)를 판별하는 D_x and G(x)를 판별하는 D_y가 있다.
논문에서는 CycleGAN은 생성된 이미지의 분포를 대상 도메인의 데이터 분포와 일치시키기 위한 Adversarial loss 와 학습된 매핑G와 F가 서로 모순되는 것을 방지하기 위해
Cycle cinsisitency loss 를 포함한다, 여기서 말하는 모순은 아래 Cycle consistency loss에서 설명한다.

### Adversarial loss

![loss](https://latex.codecogs.com/gif.latex?L_%7BGAN%7D%28G%2C%20D_Y%2C%20X%2C%20Y%29%20%3D%20%5Cmathbb%7BE%7D_%7By%5Csim%20p_%7Bdata%28y%29%7D%7D%5BlogD_Y%28y%29%5D%20+%20%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_%7Bdata%28x%29%7D%7D%5Blog%281-D_Y%28G%28x%29%29%29%5D)

위의 수식은 pix2pix에서 설명이 부족했던 것 같다. 손실함수는 최소화가 되어야 하기 때문에 G 와 F (F 와 D_x 가 동일하게 들어간다)가 위 함수를 최소화하려 하고
D_X , D_Y는 최대화 하려 한다. 결국 `min F,G max D_x,D_y L_GAN` 이라 할 수 있다.  

### Cycle Consistency Loss

Adversarial training으로 각각 대상 도메인 T와 X로 동일하게 분포된 출력을 생성하는 mapping G와 F를 배울 수 있지만 이 과정만을 하다보면 생성자(generator)가 오직 구분자(discriminator)만을 속이기 위해 하나의 모델만을
생성하기 시작한다 이를 mode collapse 문제라고 하는데 __가능한 매핑함수의 공간을 줄이기 위해__, 아래의 그림(b),(c)와 같이 매핑 함수 는 cycle-consistent해야 한다.

![c-loss](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frrcai%2FbtqCpRGNjGW%2FPCEnfXqg7nc0KQHFXeGbe0%2Fimg.png)

이러한 행동을 cycle consistency loss를 이용해 유도하였다. 식은 아래와 같다

![b,c](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdn5HM3%2FbtqCqNjM0El%2FfOaS8OoRppXhkL3J0jh970%2Fimg.png)

예비 실험에서 우리는 위식의 L1 norm을 adversarial loss로 대체됬으나 성능 향상을 관찰할 수 없었다, Cycle consistency loss 가 유도한 결과는 아래 그림을 보자\

![example](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv0yUx%2FbtqCtXsaHYJ%2FXCyjzpBa3IKbnUqQcazTY1%2Fimg.png)

### Full objective

따라서 목적함수의 전체는 이렇게 된다.

![object](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FRNX6V%2FbtqCoQ86Voc%2FxpkxPvx2kHs3u4KTHLRKFk%2Fimg.png)

이때 λ는 두함수(위식에서 첫항과 두번째항)의 상대적인 중요도에 따라 결정된다.

### Traing details

모델학습과정을 안정화 시키기 위해 논문에서는 두가지 방식을 소개하였다. 첫버쨰는 L_GAN의 negative log lokelihood 대신에 least-squared loss로 대체했다는 점인데   
least-sqiared loss는 http://jaejunyoo.blogspot.com/2017/03/lsgan-1.html의 사이트에서 자세히 설명한다.  
이 loss가 학습과정에서 더 안정적이었고 더 좋은 품질의 결과를 보여주었다. 두번쨰는 모델의 진동(oscillation)을 줄이기 위해 discriminator를 최신의 generator가 생성한 하나의 이미지를 이용하기 보다는 지금까지 생성된 이미지들 을 사용했다는 것이다.
논문에서는 이전에 생성된 50개의 이미지를 저장할 수 있는 버퍼를 이용하였다.  

![exam](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0A5i8%2FbtqCn1iPfaW%2FcRwPLt9Ufr9Cc08IdMbpF0%2Fimg.png)

위는 그 결과이다.












