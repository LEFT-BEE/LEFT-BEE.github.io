---
title: "Conditional GAN 예제코드(건물을 만들어보자 with TensorFlow examplecode"
categories: GAN
use_math: true
comments: true
---


## Tensorflow example code

`
import tensorflow as tf

import os
import time
from matplotlib import pyplot as plt
from IPython import display

#Load the dataset

_URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz'

path_to_zip = tf.keras.utils.get_file('facades.tar.gz',
                                      origin=_URL,
                                      extract=True)
#256 x 256 size
PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')
`
기본적인 세팅과 학습에 필요한 데이터를 가져온다.

`
BUFFER_SIZE = 400#의문
BATCH_SIZE = 1
IMG_WIDTH = 256
IMG_HEIGHT = 256

def load(image_file):
  image = tf.io.read_file(image_file)
  image = tf.image.decode_jpeg(image)# 이미지파일을 잘손질

  w = tf.shape(image)[1] #w = tf.Tensor(512, shape=(), dtype=int32) 의 형태이다
  w = w// 2 # 256으로 변환
   #// 나누기 연산후 소수점 이하의 수를 버리고, 정수부분의 수만 구함
  real_image = image[:, :w, :]#앞에있는게 real데이터
  input_image = image[: ,w:, :] #데이터자체가 반으로 나뉘어진것일것  아 걍 그렇다고 하자 데이터가

  input_image = tf.cast(input_image, tf.float32)
  real_image = tf.cast(real_image, tf.float32)

  return input_image, real_image #input image = 내가가진 데이터 , real_data =  워너비 실제데이터
  `
  
  BUFFER_SIZE는 무슨의미인지 아직 불명이다..   
  load()함수는 이미지 파일을 입력받아 데이터를 반으로 나누어 real_data와 input_data로 나눈다 
  
  
  `
  inp,re = load(PATH+'train/100.jpg')
# casting to int for matplotlib to show the image
plt.figure()
plt.imshow(inp/255.0)#값을 바꾸면서 본 결과로 밝기를 조절할수 있다 즉 0으로 갈수록 어두워지며 1로 갈수록 밝아진다
plt.figure()
plt.imshow(re/255.0)
`
데이터를 확인해 보도록 하자.

![2](https://user-images.githubusercontent.com/65720894/89540699-5e4b9000-d838-11ea-95df-9bd993e6d629.PNG)

위가 input_image 아래가 real_image이다. 255.0으로 나눠주는 것은 각 픽셀의 밝기가 0~1부터의 밝기로 이루어져서이다.

`
def resize(input_iamge , real_image, height, width):
  input_image = tf.image.resize(input_image, [height, width],
                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
  real_image = tf.image.resize(real_image, [height, width],
                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
  
  return input_image, real_image #학습에 알맞게 resize해준다
#위 함수는 지터링을 위해 더 큰 높이(286pix)와 너비(286pix)로 이미지 크기를 조정한다. 
`

`
def random_crop(input_image, real_image):
  stacked_image = tf.stack([input_image, real_image], axis=0)#stack 함수는  행렬를 합친다 즉 두 데이터를 합침
  cropped_image = tf.image.random_crop(
      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])# 마지막은 체널이고 첫번쨰는?
  
# tf.random_crop 함수는 첫 번째 파라미터로 받은 텐서타입의 이미지들을 
#두 번째 파라미터로 받은 크기로 무작위로 잘라 첫 번째 받은 파라미터와 같은 rank의 텐서 형태로 돌려준다.

  return cropped_image[0], cropped_image[1]
#256pix인 대상크기로 무작위 자르기를 한다. - 이를jitter라고 하는데 논문에서 소개하고있으니 해보도록 하자
`
`
 # normalizing the images to [-1, 1]

def normalize(input_image, real_image):
  input_image = (input_image / 127.5) - 1
  real_image = (real_image / 127.5) - 1

  return input_image, real_image
  `
  `
  def random_jitter(input_image, real_image):
  # resizing to 286 x 286 x 3
  input_image, real_image = resize(input_image, real_image, 286, 286)#286으로 재조정

  # randomly cropping to 256 x 256 x 3
  input_image, real_image = random_crop(input_image, real_image)#256사이즈로 랜덤하게 자른다. 아마 학습
  #률을 높이기위해(분포값을 늘리기위해?)

  if tf.random.uniform(()) > 0.5:#균일 한 분포로부터의 출력값을 랜덤.
    # random mirroring
    input_image = tf.image.flip_left_right(input_image)
    real_image = tf.image.flip_left_right(real_image)#이미지 d

  return input_image, real_image
  `
  
  코드가 길어졌는데 사실 내용은 별거 없다. jitter와 mirriring을 해주었는데 그 이유는 CGAN 논문에서 학습률에 도움을 준다고 하여 집어넣었다. 예상하는 바로는 각 이미지 데이터의 분포를 항상 랜덤하게 만들어 학습이 더 효과적으로 이루어질 수 있게 하는것이라 생각한다.
  ![1](https://user-images.githubusercontent.com/65720894/89540695-5d1a6300-d838-11ea-804f-87aec51fcd59.PNG)
  
  

