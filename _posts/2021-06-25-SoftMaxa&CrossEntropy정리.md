---
title : "최대우도측정과 SoftMax 분류기 그리고 CrossEntropy까지"
categories : "cs231"
---

## 최대 우도 측정

우도란(가능성/가능도) - 나타난 결과에 따라 여러 가능한 가설들을 평가할 수 있는 측도(Measure)

최대우도 - 나타난 결과에 해당하는 각 가설마다 계산된 우도 값 중 가장 큰 값을 말함. 일어날 가능성(우도)이 가장 큰 것을 나타냄, 즉 관측된
랜덤표본에 해당하는 여러 가설중 우도 함수 값이 최대 인것 

-------------

#### 최대 우도 추정치(ML estimator)

-우도 함수 L(theata)를 최대로 하는 모수 theta값에 대한 추정치를 theta_라고 한다면 이는 우도함수를 미분한 값이 0이 되게 하으로 찾는다

-우도함수를 편 미분하여 0으로 두고, 미지의 모수인 추정치를 구하게 되는데 여기서 편 미분의 사용 이유는 우도 함수가 표본값 xI와 모수 theta에
모두 의존하기 때문이다.



#### 최대 우도 추정법

![image](https://user-images.githubusercontent.com/65720894/123300848-f1c3a780-d555-11eb-92e3-4b837b3393af.png)

위 그림처럼 결과값이 나타날 수 있는 최대한의 확률분포를 확률로 만들어낸다

-최대우도 원리란 나타난 결과는 여러 원인 중 일어날 가능성(조건부 확률)이 가장 큰 원인에서 비롯된다는 원리를 말한다.

-최대 우도 추정법은 우도함수를 최대화 하면서 모수를 추정하는 방법인데 관측된 표본에 기초하여 관측 불가능한 파라미터(모수)를 추정하는 방법론
중 하나이다 다시말해 표본들로부터 알려지지 않은 모집단 확률분포의 형태를 추정해가는 방법론이다.

-최대우도 측정법은 모집단이 어떤 종류의 확률 분포를 하는지 정도는 알고 있으나 구체적으로 모집단을 나타내는 수치를 모르는 경우에 주로 사용한다

![image](https://user-images.githubusercontent.com/65720894/123356169-22313300-d5a2-11eb-954c-02aa521762ea.png)

#### 최대우도 추정법 쉽게 이해하기

우도의 개념을 단순하게 정의하면 확률가 그 의미가 대칭되는 것과 같다. 다시 말해 확률에서는 모비율이 특정되어있고 불변인데 그 위에서 관찰된 값이 
나오는 반면(동전을 던질 때 앞면이 나올 확률은 일반적으로 1/2이며 그것을 바탕으로 특정 관찰이 나올 확률을 계산한다) 우도의 개념에서는 역으로
관찰치는 고정되어있고 그것이 가장 잘 그럴 듯하게 나오는 모수 값을 찾아내는 것이다(확률분포를 찾아나감)

 이를 2차원 그래프로 나타내면 확률 분포곡선에서 특정한 포인트를 찍어서 확률을 계산하는 확률과는 정반대로 우도의 개념에서는 특정한 관찰값이 이미
 주어져있고 이에 끼워맞추어 그 관찰값이 제일 잘 나오는 확률분포곡선의 위치를 찾는 것이 그 목적이다. 이는 회귀문제와도 비슷하다고 볼 수 있는데
 데이터셋을 설명하는데 있어 가장 그럴듯한 가설 h(x)를 찾는 과정과 비슷하다.
 
 이는 일반적인 회귀분석이 갖고 있는 문제점과 한계점에 대응하기 위한 것이 일부이며 이것이 갖고 있는 최대의 문제점인 계산문제가 컴퓨터의 발전으로
 해결되었기 떄문이다. 특정한 확률분포를 사용해 계산하여 우도를 구하고, 그 분포를 약간 이동시켜 또 우도를 구하고 반복하다가 그 우도가 최대로 결정되는 지점에서
 멈추는 것이다
 
 마지막으로 최대우도 추정의 가장 큰 장점 중 하나는 확률 분포의 종류만 정해지면 게산방식은 모두 동일하다는 것이다. 특히 일반적인 방식에서 각각 모두 다른
 표준오차의 추정 역시 같은 방식으로 계산되며 표현될 수 있다는 것 이는 결국 확률분포만 확보해 표현할 수 있다면- 일반적인 routine으로 처리 할 수 있다는
 과정을 시사한다, 아울러 최대우도 추정은 특정한 어떤 분포가 아니라 그런 방식을 사용하는 분석방법을 통칭하는 일종의 전략이라 생각하도록 하자
 
 --------------------------------------
 
 
 
 ## Classfication문제에서 CrossEntropy를 사용하는 원리와 방법론 
 
 ![image](https://user-images.githubusercontent.com/65720894/123356760-43deea00-d5a3-11eb-9efd-367026ef1722.png)
 
 위 수식은 cross entropy의 일반식 아래식은 binary cross entropy의 식이다
 
 -------
 
 ![image](https://user-images.githubusercontent.com/65720894/123357179-10e92600-d5a4-11eb-981a-e48e03d3479a.png)
 
 - Multi-Class Classfication

각 샘플은 클래스 C중 하나로 분류 될 수 있다. 해는 0번 [1,0,0] 달은 1번, [0 1 0],구름은 2번, [0 0 1]으로 분류될 수 있다는 것이다.

CNN은 s(scroe)벡터를 출력하고 one hot 벡터인 타겟벡터와 t와 매칭이 되어 loss값을 계산할 것이다 즉, Multi-Class Classification은 여러 샘플(이미지)에서 C개의 클래스 중 하나의 클래스로 분류하는 문제로 생각할 수 있다.


### 활성화 함수(Activation Function)

Sigmoid 와 softmax 함수가 있고 이 중 softmax함수는 클래스의 스코어를 나타내는 벡터 각각의 요소는 (0,1)이 되며, 모든 합이 1이 되도록 만들어 준다 s_j는 각 스코어이고 모든 i에대해 소프트 맥스 값을 더하면 1이 나온다.

![images2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbecyu2%2FbtqxaE6zhbc%2FWbKnWLKN58shWQrkbyscJk%2Fimg.png)


## Cross Entropy의 대한 

