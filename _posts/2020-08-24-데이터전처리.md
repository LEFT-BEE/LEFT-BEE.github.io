---
title: "데이터 전처리"
date: 2020-08-20
---

인공신경망은 설계가 구현 이상으로 중요하다. 설게와 구현의 최적화가 performance에 미치는 비중으로 치자면 이론적 설계 단계가 훨씬 더 높은 가중치를 
지니고 있다. 그 설계의 부분에서도 비중이 큰것이 바로 데이터의 전처리이다.

디지털화 가능한 모든 종류의 데이터를 분석할 수 있는 인공신경망 분석모델을 구축하는데 있어서, 중요한 것은 어떤 데이터를 어떤 방식으로 어떻게 가공하여 어떤식으로
출력할지에 대해 설계하는 것이다.

'데이터 주도 학습'이니 어떤 데이터가 주입되는지가 가장 중요한 것은 당연한일.. 정확도를 일정 부분 이상(실용성의 임계점)으로 끌어올리는
방법으로, 이러한 데이터 전처리를 행하거나, 혹은 데이터 전처리 이후에만 나오는 정보 역시 존재하기에 이는 무척 중요한 일이다. 따라서 데이터를 적적한 형태로 가공해줘야한다.

텐서플로의 keras모듈 역시 이러한 데이터 전처리를 위한 기법을 제공해준다.

ex)자연어 처리 데이터 전처리 예시

### 1.라이브러리 import

`import os`
`import tensorflow as tf`
`import numpy as np`
`form tensorflow,keras import preprocessing`

:주로 tf의 data모듈과 keras모듈의 preprocessing을 사용할 것이다,

### 2.언어 데이터 및 정답 레이블 준비

`sample = ['너 정말 예쁘다' , '나는 오늘 화났다' , '길동이가 오늘 기분이 좋은가봐', '정말 끝내주는 날이야', '재정말 화났어','굉장한데? 진짜 좋다']`

`label = [[1],[0],[1],[1],[0],[1]]`

여기서 규칙성은 사람이 판단하기에 긍정적인 문장은 1 , 부정적인 문장은 0으로 나눈 것이다. 여기서 데이터와 라벨의 의미는, 머신러닝 모델을 학습시킬 때의 기준을 의마한다.
이러한 문장은 1로 긍정 저러한 문장은 0으로 부정..이런식이다.

즉 데이터와 라벨을 잘 준비하는 것은 무척 중요한 일이고, 모델 자체는 추후 이에 맞게 시도를 해나가며 변경하면 된다. 이제 자연어 데이터와 정답이 준비됬다.
아래부터는 데이털르 사용하기 쉽게 가공하는 작업, 즉 데이터 전처리를 실행해 보자.

### 3. 데이터 토큰화 

`tokenizer = preprocessing.text.Tokenizer()`
`tokenizer.fit_on_texts(samples)`
`sequences = tokenizer.texts_to_sequences(samples)`
`word_index = tokenizer.word_index`


